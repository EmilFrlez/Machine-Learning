{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LymphkillTensorflowKeras.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"xzDLcOs6Yz8q","colab_type":"code","outputId":"032cdb84-6c04-4a0c-bedc-ddbdcbea865e","executionInfo":{"status":"error","timestamp":1545244485860,"user_tz":300,"elapsed":134146,"user":{"displayName":"Dinko Pocanic","photoUrl":"https://lh4.googleusercontent.com/-2AxkkaPmOyA/AAAAAAAAAAI/AAAAAAAAAD8/NiBIgF9Vz_E/s64/photo.jpg","userId":"10748866867040160290"}},"colab":{"base_uri":"https://localhost:8080/","height":1646}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","\n","# load dataset\n","\n","dataframe = pd.read_csv(\"/content/drive/My Drive/cancer_data.csv\", delim_whitespace=True, header=None) \n","dataset = dataframe.values"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n"],"name":"stdout"},{"output_type":"error","ename":"TIMEOUT","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTIMEOUT\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTIMEOUT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timeout exceeded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTIMEOUT\u001b[0m: Timeout exceeded.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTIMEOUT\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ef481c9fd97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount)\u001b[0m\n\u001b[1;32m    120\u001b[0m     case = d.expect([\n\u001b[1;32m    121\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0m_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'(Go to this URL in a browser: https://.*)\\r\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     ])\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         return self.expect_list(compiled_pattern_list,\n\u001b[0;32m--> 341\u001b[0;31m                 timeout, searchwindowsize, async_)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     def expect_list(self, pattern_list, timeout=-1, searchwindowsize=-1,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTIMEOUT\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mtimeout\u001b[0;34m(self, err)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTIMEOUT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTIMEOUT\u001b[0m: Timeout exceeded.\n<pexpect.pty_spawn.spawn object at 0x7f0d363aadd8>\ncommand: /bin/bash\nargs: [b'/bin/bash', b'--noediting']\nbuffer (last 100 chars): 'n.cc:494:operator() Trace successfully written\\r\\nroot@4d8ac1e248ae-7891509cba7341bf8bd2ce3efd491d94: '\nbefore (last 100 chars): 'n.cc:494:operator() Trace successfully written\\r\\nroot@4d8ac1e248ae-7891509cba7341bf8bd2ce3efd491d94: '\nafter: <class 'pexpect.exceptions.TIMEOUT'>\nmatch: None\nmatch_index: None\nexitstatus: None\nflag_eof: False\npid: 100\nchild_fd: 60\nclosed: False\ntimeout: 120\ndelimiter: <class 'pexpect.exceptions.EOF'>\nlogfile: None\nlogfile_read: None\nlogfile_send: None\nmaxread: 1000000\nignorecase: False\nsearchwindowsize: None\ndelaybeforesend: 0.05\ndelayafterclose: 0.1\ndelayafterterminate: 0.1\nsearcher: searcher_re:\n    0: re.compile('google.colab.drive MOUNTED')\n    1: re.compile('Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\\n\\nEnter your authorization code:\\n')\n    2: re.compile('(Go to this URL in a browser: https://.*)\\r\\n')"]}]},{"metadata":{"id":"6Xgg55fF58s-","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"DI1BYB6aZjQU","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"qGo3fGW5hNs4","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"q8H8l7Y0Yz8S","colab_type":"text"},"cell_type":"markdown","source":["# Regresion of Lymphocyte Count  Using Keras and TensorFlow\n","\n","We will create a neural network model with Keras. We will also use scikit-learn to evaluate models using cross-validation. Finally, we will tune the network topology of models with Keras. My backend will be TensorFlow."]},{"metadata":{"id":"wPadnJx-Yz8g","colab_type":"text"},"cell_type":"markdown","source":["## Visualizing Dataset"]},{"metadata":{"id":"aYUhEqbpYz9O","colab_type":"text"},"cell_type":"markdown","source":["### Attributes\n","\n"," 0. AOMAX: Aorta maximum dose (Gy)\n"," 1. AOMEA: Aorta mean dose (Gy)\n"," 2. AOVOL: Aorta total volume (cm^3)\n"," 3. AOINT: Aorta integral dose (Gy)\n"," 4. AOV5:  Aorta V5 (cm^3)\n"," 5. AOV10: Aorta V10 (cm^3)\n"," 6. AOV15: Aorta V15 (cm^3)\n"," 7. AOV20: Aorta V20 (cm^3)\n"," 8. VO: Partial tumor volume (cm^3) \n"," 9. LA0:  Pre-treatment, initial LYA count (cells/l/10^9)\n"," 10. DAYS:  Days elapsed since start of the treatment.\n"," 11. BEAM:  Beam energy index\n"," 12. AGE:   Patient age (years)\n"," 13. LYA: Final LYA count (cells/l/10^9)\n"]},{"metadata":{"id":"FF0LxrNSYz9S","colab_type":"code","colab":{}},"cell_type":"code","source":["dataframe.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ouqui2qiYz9u","colab_type":"text"},"cell_type":"markdown","source":["### As you can see, with higher aorta integral dose, lymphocyte loss increases. What else could we predict with Neural Networks using Keras and TensorFlow?"]},{"metadata":{"id":"8VbJEgGpYz9y","colab_type":"code","colab":{}},"cell_type":"code","source":["import seaborn as sns\n","\n","new_df = pd.concat([dataframe[3], dataframe[9]-dataframe[13]], axis=1)\n","new_df.columns = ['Aorta Integral Dose (Gy)', 'Lymphocyte Decrease/10^9/l']\n","sns.jointplot(x='Lymphocyte Decrease/10^9/l', y='Aorta Integral Dose (Gy)', data=new_df)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rILIrJ8lYz-C","colab_type":"text"},"cell_type":"markdown","source":["## Develop a Baseline Neural Network Model"]},{"metadata":{"id":"YQQUWY8nYz-G","colab_type":"code","colab":{}},"cell_type":"code","source":["# Regression Example With Lymphocyte Dataset: Baseline\n","import numpy\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","# load dataset\n","dataframe = read_csv(\"/content/drive/My Drive/cancer_data.csv\", delim_whitespace=True, header=None)\n","dataset = dataframe.values\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:13]\n","Y = dataset[:,13]\n","# define base model\n","def baseline_model():\n","\t# create model\n","\tmodel = Sequential()\n","\tmodel.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n","\tmodel.add(Dense(1, kernel_initializer='normal'))\n","\t# Compile model\n","\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n","\treturn model\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","# evaluate model\n","estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n","kfold = KFold(n_splits=10, random_state=seed)\n","results = cross_val_score(estimator, X, Y, cv=kfold)\n","print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n","\n","#import seaborn as sns\n","#Z=baseline_model().predict(X)\n","#df1 = pd.concat( [Z, Y], axis=1)\n","#df1.columns = ['Measured', 'Predicted']\n","#sns.joinplot(x='Predicted', y='Measured', data=df1)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mU_LJhAqwjP-","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"HgYAGnqrsquu","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"JYuN6y5YsrKM","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"dbBYKzD0Yz-e","colab_type":"text"},"cell_type":"markdown","source":["## Lift Performance By Standardizing the Dataset\n","\n","Knowing that each attribute in the Lymphocyte dataset measures in different scales, we could standardize everything to get better results. We are going to use scikit-learn's Pipeline feature within each fold of the cross-validation."]},{"metadata":{"id":"75YkofydYz-q","colab_type":"code","colab":{}},"cell_type":"code","source":["# Regression Example With Lymphocyte Dataset: Standardized\n","import numpy\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","# load dataset\n","dataframe = read_csv(\"/content/drive/My Drive/cancer_data.csv\", delim_whitespace=True, header=None)\n","dataset = dataframe.values\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:13]\n","Y = dataset[:,13]\n","# define base model\n","def baseline_model():\n","\t# create model\n","\tmodel = Sequential()\n","\tmodel.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n","\tmodel.add(Dense(1, kernel_initializer='normal'))\n","\t# Compile model\n","\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n","\treturn model\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","# evaluate model with standardized dataset\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = KFold(n_splits=10, random_state=seed)\n","results = cross_val_score(pipeline, X, Y, cv=kfold)\n","print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9aIP3VaMYz-4","colab_type":"text"},"cell_type":"markdown","source":["## Tuning the Neural Network Topology\n","Now that we have utilized k-folds for cross-validiation and standardization of datasets, let's work on expanding our Neural Network.\n","\n","### Making our Neural Network even Deeper\n","Here we add more layers and neurons in each layer of our neural network."]},{"metadata":{"id":"1TXO2ag0Yz-8","colab_type":"code","colab":{}},"cell_type":"code","source":["# Regression Example With Lymphocyte Dataset: Standardized and Larger\n","import numpy\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","# load dataset\n","dataframe = read_csv(\"/content/drive/My Drive/cancer_data.csv\", delim_whitespace=True, header=None)\n","dataset = dataframe.values\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:13]\n","Y = dataset[:,13]\n","# define the model\n","def larger_model():\n","\t# create model\n","\tmodel = Sequential()\n","\tmodel.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))\n","\tmodel.add(Dense(6, kernel_initializer='normal', activation='relu'))\n","\tmodel.add(Dense(1, kernel_initializer='normal'))\n","\t# Compile model\n","\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n","\treturn model\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","# evaluate model with standardized dataset\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = KFold(n_splits=10, random_state=seed)\n","results = cross_val_score(pipeline, X, Y, cv=kfold)\n","print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Iza2fgJxYz_U","colab_type":"text"},"cell_type":"markdown","source":["### Making our Neural Network even Wider\n","Now, we roughly double our neuron count from 13 to 20 inputs."]},{"metadata":{"id":"_dvB6nx1Yz_U","colab_type":"code","colab":{}},"cell_type":"code","source":["# Regression Example With Lymphocyte Dataset: Standardized and Wider\n","import numpy\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","# load dataset\n","dataframe = read_csv(\"/content/drive/My Drive/cancer_data.csv\", delim_whitespace=True, header=None)\n","dataset = dataframe.values\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:13]\n","Y = dataset[:,13]\n","# define wider model\n","def wider_model():\n","\t# create model\n","\tmodel = Sequential()\n","\tmodel.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))\n","\tmodel.add(Dense(1, kernel_initializer='normal'))\n","\t# Compile model\n","\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n","\treturn model\n","# fix random seed for reproducibility\n","seed = 7\n","numpy.random.seed(seed)\n","# evaluate model with standardized dataset\n","#estimators = []\n","#estimators.append(('standardize', StandardScaler()))\n","#estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n","#pipeline = Pipeline(estimators)\n","#kfold = KFold(n_splits=10, random_state=seed)\n","#results = cross_val_score(pipeline, X, Y, cv=kfold)\n","#print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n","\n","# extract predictions\n","estimator = KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)\n","estimator.fit(X, Y)\n","predictions = estimator.predict(X)\n","\n","train_error =  numpy.abs(Y - predictions)\n","mean_error = numpy.mean(train_error)\n","min_error = numpy.min(train_error)\n","max_error = numpy.max(train_error)\n","std_error = numpy.std(train_error)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.scatter(Y, predictions)\n","plt.xlabel('True LYA Decrease [cells/]/1E9')\n","plt.ylabel('Predicted LYA Decrease [cells/l/1E9]')\n","plt.axis('equal')\n","plt.xlim(plt.xlim())\n","plt.ylim(plt.ylim())\n","_ = plt.plot([-2, 2], [-2, 2])\n","\n","# load new patient, change age 77->17 years\n","dataframeNew = read_csv(\"/content/drive/My Drive/new-patient.csv\", delim_whitespace=True, header=None)\n","dataset = dataframeNew.values\n","XNew = dataset[:,0:13]\n","print(estimator.predict(XNew))\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pHu7aZGvYz_e","colab_type":"text"},"cell_type":"markdown","source":["## Conclusion\n","\n","Our baseline model using Keras, TensorFlow, and SciKit-Learn scored: -0.41  (0.21) MSE. However, with standardizing our dataset, tuning our neural network by making our neural network deeper and wider, we were able to score a final  -0.02 (0.02) MSE. That's over a $10,000 improvement in mean-squared-error!"]},{"metadata":{"id":"2uNrsHiZaOCa","colab_type":"text"},"cell_type":"markdown","source":[""]}]}